{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ff5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3df6f99e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T06:16:43.935889Z",
     "iopub.status.busy": "2024-02-06T06:16:43.935468Z",
     "iopub.status.idle": "2024-02-06T06:16:43.962451Z",
     "shell.execute_reply": "2024-02-06T06:16:43.960821Z",
     "shell.execute_reply.started": "2024-02-06T06:16:43.935857Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from openai import OpenAI # for calling the OpenAI API\n",
    "import tiktoken  # for counting tokens\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import os # for getting API token from env variable OPENAI_API_KEY\n",
    "import glob\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from string import Template\n",
    "\n",
    "# models\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "562c9fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T06:11:43.429009Z",
     "iopub.status.busy": "2024-02-06T06:11:43.428413Z",
     "iopub.status.idle": "2024-02-06T06:11:43.435925Z",
     "shell.execute_reply": "2024-02-06T06:11:43.435084Z",
     "shell.execute_reply.started": "2024-02-06T06:11:43.428974Z"
    }
   },
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87c28a75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T06:11:43.438684Z",
     "iopub.status.busy": "2024-02-06T06:11:43.438175Z",
     "iopub.status.idle": "2024-02-06T06:11:43.453167Z",
     "shell.execute_reply": "2024-02-06T06:11:43.451773Z",
     "shell.execute_reply.started": "2024-02-06T06:11:43.438654Z"
    }
   },
   "outputs": [],
   "source": [
    "def construct_message(task):\n",
    "    token_budget = 4000\n",
    "\n",
    "    description = \\\n",
    "\"\"\"\\\n",
    "\\\"Given a series of input-output pairs of grids to train on, find the rule that transforms \\\n",
    "input grids to output grids. Then use that rule on the test input grid to produce test \\\n",
    "output grids. Only write the outputs and nothing else. If there are multiple test inputs, \\\n",
    "separate the multiple test outputs with a semicolon ';'. Each test output should be outputed \\\n",
    "as a 2D array, using square brackets and commas to separate. \\\n",
    "\"\"\"\n",
    "\n",
    "    message_template = Template(description + \\\n",
    "\"\"\"\\\n",
    "Here are the training pairs:\\\\n\\\\n\\\n",
    "$train_pairs\\\\n\\\\n\\\n",
    "Here are the testing inputs:\\\\n\\\\n\\\n",
    "$testing_inputs\\\"\\\n",
    "\"\"\")\n",
    "\n",
    "    testing_inputs = ';'.join([str(pair['input']) for pair in task['test']]).replace(' ', '')\n",
    "    message = message_template.substitute(\n",
    "        train_pairs='',\n",
    "        testing_inputs=testing_inputs\n",
    "    )\n",
    "    for i in range(len(task['train'])):\n",
    "        message_with_added_pair = message_template.substitute(\n",
    "            train_pairs=str(task['train'][0:i+1]).replace(' ', ''),\n",
    "            testing_inputs=testing_inputs\n",
    "        )\n",
    "        if num_tokens(message_with_added_pair) < token_budget:\n",
    "            message = message_with_added_pair\n",
    "        \n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "106e38e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T06:52:16.178945Z",
     "iopub.status.busy": "2024-02-06T06:52:16.178354Z",
     "iopub.status.idle": "2024-02-06T06:52:16.187238Z",
     "shell.execute_reply": "2024-02-06T06:52:16.185766Z",
     "shell.execute_reply.started": "2024-02-06T06:52:16.178903Z"
    }
   },
   "outputs": [],
   "source": [
    "def flattener(pred):\n",
    "    str_pred = str([row for row in pred])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    return str_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d83e35c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T06:57:22.164292Z",
     "iopub.status.busy": "2024-02-06T06:57:22.163849Z",
     "iopub.status.idle": "2024-02-06T06:57:23.086407Z",
     "shell.execute_reply": "2024-02-06T06:57:23.084994Z",
     "shell.execute_reply.started": "2024-02-06T06:57:22.164259Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('submission.csv', 'w') as output_file:\n",
    "    output_file.write('output_id,output\\n')\n",
    "    for idx, file_name in enumerate(glob.glob('../input/abstraction-and-reasoning-challenge/test/*.json')):\n",
    "        print(idx, end='\\r')\n",
    "        with open(file_name, 'r') as test_task_file:\n",
    "            test_task = json.load(test_task_file)\n",
    "            messages = [\n",
    "                {'role': 'system', 'content': 'You learn rules which transform input grids into output grids.'},\n",
    "                {'role': 'user', 'content': construct_message(test_task)},\n",
    "            ]\n",
    "            response = client.chat.completions.create(\n",
    "                model='ft:gpt-3.5-turbo-0613:personal:arc:8oomlieW',\n",
    "                messages=messages,\n",
    "                temperature=0\n",
    "            )\n",
    "            responses = response.choices[0].message.content.split(';')\n",
    "            for i in range(len(responses)):\n",
    "                try:\n",
    "                    output = flattener(eval(responses[i]))\n",
    "                    output_file.write(f'{file_name.split(\"/\")[-1].split(\".\")[0]}_{i},{output}\\n')\n",
    "                except: \n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c116d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 967687,
     "sourceId": 18329,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
